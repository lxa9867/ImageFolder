experiment:
  project: rar
  name: rar_b
  max_train_examples: 1281167
  save_every: 50000
  eval_every: 50000
  generate_every: 5000
  log_every: 50
  log_grad_norm_every: 1000
  resume: true
  output_dir: rar_b
  logging_dir: rar_b/logs
model:
  vq_ckpt: RobustTok.pt
  ema: true
  vq_model:
    codebook_size: 4096
    codebook_embed_dim: 64
    codebook_l2_norm: true
    dropout_p: 0.0
    v_patch_nums:
    - 16
    enc_type: dinov2
    dec_type: dinov2
    semantic_guide: dinov2
    detail_guide: none
    num_latent_tokens: 256
    encoder_model: vit_base_patch14_dinov2.lvd142m
    decoder_model: vit_base_patch14_dinov2.lvd142m
    abs_pos_embed: true
    product_quant: 1
    codebook_drop: 0.1
    half_sem: false
    guide_type_1: class
    guide_type_2: class
    lfq: false
  generator:
    hidden_size: 768
    num_hidden_layers: 24
    num_attention_heads: 16
    intermediate_size: 3072
    dropout: 0.1
    attn_drop: 0.1
    class_label_dropout: 0.1
    image_seq_len: 256
    condition_num_classes: 1000
    randomize_temperature: 1.0
    guidance_scale: 16.0
    guidance_scale_pow: 2.75
    use_checkpoint: false
    randomness_anneal_start: 125000
    randomness_anneal_end: 187500
dataset:
  params:
    pretokenization: /media/Bootes/kaiqiu/RAR-data/RobustTok/pretokenized.jsonl
    train_shards_path_or_url: imagenet_sharded/train/imagenet-train-{0000..0252}.tar
    eval_shards_path_or_url: imagenet_sharded/val/imagenet-val-{0000..0009}.tar
    num_workers_per_gpu: 12
  preprocessing:
    resize_shorter_edge: 256
    crop_size: 256
    random_crop: false
    random_flip: true
optimizer:
  name: adamw
  params:
    learning_rate: 0.0004
    beta1: 0.9
    beta2: 0.96
    weight_decay: 0.03
lr_scheduler:
  scheduler: cosine
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 62500
    end_lr: 1.0e-05
training:
  gradient_accumulation_steps: 16
  per_gpu_batch_size: 32
  mixed_precision: bf16
  enable_tf32: true
  enable_wandb: true
  use_ema: false
  seed: 42
  max_train_steps: 250000
  max_grad_norm: 1.0
config: configs/generator/robustTok-rar.yaml
